{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PRACTICA 3 - Business Score Analysis Report\n",
    "## 2. Reviews Analysis\n",
    "#### Ignacio González - Saúl Segura\n",
    "##### 08/01/2023\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data\n",
    "We load the file 'yelp_academic_dataset_review.json' in JSON format and transform it to CSV files in order to reduce its disk size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in the json file\n",
    "review_json = pd.read_json('../data/raw/yelp_academic_dataset_review.json', lines=True)\n",
    "# convert the json file to a csv\n",
    "review_json.to_csv('../data/raw/review.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we notice that the data size of 'review.csv' is still considerably large, we proceed to create a function 'split_csv' that splits and generates a set of new CSV files with the number of lines we see fit.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_csv(file_name: str, max_lines: int, base_name: str):\n",
    "    \"\"\"Split a large CSV file into smaller files with a maximum number of lines.\n",
    "\n",
    "    Args:\n",
    "      file_name: Name of the original CSV file.\n",
    "      max_lines: Maximum number of lines per file.\n",
    "      base_name: Base name for the generated files.\n",
    "    \"\"\"\n",
    "    # Counter to keep track of the file number\n",
    "    i = 0\n",
    "\n",
    "    # Read the original file using pandas\n",
    "    df = pd.read_csv(file_name)\n",
    "\n",
    "    # Calculate the number of chunks needed\n",
    "    num_chunks = (len(df) // max_lines) + 1\n",
    "\n",
    "    # Split the DataFrame into chunks\n",
    "    chunks = [df.iloc[i:i+max_lines, :] for i in range(0, len(df), max_lines)]\n",
    "\n",
    "    # Iterate over the chunks\n",
    "    for chunk in chunks:\n",
    "        # Increment the counter\n",
    "        i += 1\n",
    "        # Create a new file name using the counter and the base name\n",
    "        new_file_name = f'../data/raw/{base_name}_part_{i}.csv'\n",
    "        # Write the current chunk to the new file\n",
    "        chunk.to_csv(new_file_name, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We split the file 'review.csv' into sub-files of 700 thousand rows, obtaining a total of 10 files whose size facilitates its manipulation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_csv('../data/raw/review.csv', 700000, 'review')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We note that in the reviews data, we find a column 'text' that shows the text comment that the user has entered indicating and justifying his opinion.\n",
    "\n",
    "This text comment is subjective to the user and usually very long in characters making the size of the CSV file huge, therefore in order to summarize and get the most relevant information from the comment, we designed an algorithm that obtains and summarizes the column 'text' of each review and creates a new column 'keywords' with the keywords of the comment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_csv(file_path, num_keywords=10):\n",
    "    # Load the original CSV file into a Pandas DataFrame\n",
    "    df = pd.read_csv(file_path)\n",
    "    print('0')\n",
    "\n",
    "    # Tokenize the content of the 'text' column\n",
    "    df['tokens'] = df['text'].apply(nltk.word_tokenize)\n",
    "    print('1')\n",
    "\n",
    "    # Remove stop words from the list of tokens\n",
    "    stop_words = nltk.corpus.stopwords.words('english')\n",
    "    df['tokens'] = df['tokens'].apply(lambda tokens: [token for token in tokens if token.lower() not in stop_words])\n",
    "    print('2')\n",
    "\n",
    "    # Select the most important words for each row\n",
    "    df['keywords'] = df['tokens'].apply(lambda tokens: select_important_words(tokens, num_keywords))\n",
    "    print('3')\n",
    "\n",
    "    # Drop the 'text' and 'tokens' column from the DataFrame\n",
    "    df = df.drop('text', axis=1)\n",
    "    df = df.drop('tokens', axis=1)\n",
    "\n",
    "    # Save the new DataFrame to a CSV file\n",
    "    df.to_csv(file_path.replace('.csv', '_keywords.csv'), index=False)\n",
    "\n",
    "def select_important_words(tokens, num_keywords):\n",
    "    # Calculate the frequency of each word in the list of tokens\n",
    "    fd = nltk.FreqDist(tokens)\n",
    "\n",
    "    # Select the most frequent words as keywords\n",
    "    keywords = [word for word, frequency in fd.most_common(num_keywords) if word.isalnum()]\n",
    "\n",
    "    # Tag the parts of speech of the keywords\n",
    "    pos_tags = nltk.pos_tag(keywords)\n",
    "\n",
    "    # Filter the list of keywords to include only nouns and adjectives\n",
    "    keywords = [word for word, pos in pos_tags if pos in ['NN', 'NNS', 'NNP', 'NNPS', 'JJ', 'JJR', 'JJS']]\n",
    "\n",
    "    return keywords"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We process each of the 10 files we generated earlier after splitting the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "process_csv('../data/raw/review_part_1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "process_csv('../data/raw/review_part_2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "process_csv('../data/raw/review_part_3.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "process_csv('../data/raw/review_part_4.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "process_csv('../data/raw/review_part_5.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "process_csv('../data/raw/review_part_6.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "process_csv('../data/raw/review_part_7.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "process_csv('../data/raw/review_part_8.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "process_csv('../data/raw/review_part_9.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "process_csv('../data/raw/review_part_10.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once we have used the algorithm to process and obtain the keyword for each review, we obtain a reduction of approximately 75% of the previous file size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6990280, 9)"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read each CSV file and save it to a variable\n",
    "df_review_keywords_1 = pd.read_csv('../data/processed/review_part_1_keywords.csv')\n",
    "df_review_keywords_2 = pd.read_csv('../data/processed/review_part_2_keywords.csv')\n",
    "df_review_keywords_3 = pd.read_csv('../data/processed/review_part_3_keywords.csv')\n",
    "df_review_keywords_4 = pd.read_csv('../data/processed/review_part_4_keywords.csv')\n",
    "df_review_keywords_5 = pd.read_csv('../data/processed/review_part_5_keywords.csv')\n",
    "df_review_keywords_6 = pd.read_csv('../data/processed/review_part_6_keywords.csv')\n",
    "df_review_keywords_7 = pd.read_csv('../data/processed/review_part_7_keywords.csv')\n",
    "df_review_keywords_8 = pd.read_csv('../data/processed/review_part_8_keywords.csv')\n",
    "df_review_keywords_9 = pd.read_csv('../data/processed/review_part_9_keywords.csv')\n",
    "df_review_keywords_10 = pd.read_csv('../data/processed/review_part_10_keywords.csv')\n",
    "\n",
    "# Concatenate the variables into a single DataFrame\n",
    "df_review_keywords = pd.concat([df_review_keywords_1, df_review_keywords_2, df_review_keywords_3,\n",
    "                                df_review_keywords_4, df_review_keywords_5, df_review_keywords_6,\n",
    "                                df_review_keywords_7, df_review_keywords_8, df_review_keywords_9,\n",
    "                                df_review_keywords_10])\n",
    "\n",
    "# Save the resulting DataFrame to a CSV file\n",
    "df_review_keywords.to_csv('../data/processed/review_keywords.csv', index=False)\n",
    "\n",
    "df_review_keywords.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once we have processed and generated the new file of the reviews with the keyword, the resulting csv file is 1.1GB gb in size, compared to the initial csv file of 4.67GB in size is a reduction of 76% and compared to the original json file of 5.34GB in size is a reduction of 80%."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are going to unify the data obtained in the reviews with the businesses that we have previously selected in the notebook '01_Business_Analysis'.\n",
    "\n",
    "We loaded the data with nighlife businesses in the state of Pennsylvania."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Unnamed: 0', 'Category 1', 'Category 2', 'Category 3', 'Category 4',\n",
       "       'Category 5', 'Category 6', 'Category 7', 'Category 8',\n",
       "       'BusinessAcceptsCreditCards', 'RestaurantsDelivery', 'OutdoorSeating',\n",
       "       'BikeParking', 'RestaurantsPriceRange2', 'RestaurantsTakeOut',\n",
       "       'ByAppointmentOnly', 'WiFi', 'Alcohol', 'Caters',\n",
       "       'WheelchairAccessible', 'GoodForKids', 'RestaurantsAttire',\n",
       "       'RestaurantsReservations', 'Ambience', 'CoatCheck', 'DogsAllowed',\n",
       "       'RestaurantsTableService', 'RestaurantsGoodForGroups', 'HasTV',\n",
       "       'HappyHour', 'DriveThru', 'GoodForMeal', 'NoiseLevel',\n",
       "       'BusinessAcceptsBitcoin', 'AcceptsInsurance', 'Smoking', 'Music',\n",
       "       'GoodForDancing', 'BestNights', 'BYOB', 'Corkage', 'BYOBCorkage',\n",
       "       'HairSpecializesIn', 'Open24Hours', 'RestaurantsCounterService',\n",
       "       'AgesAllowed', 'DietaryRestrictions', 'Monday', 'Tuesday', 'Wednesday',\n",
       "       'Thursday', 'Friday', 'Saturday', 'Sunday', 'business_id', 'name',\n",
       "       'address', 'city', 'state', 'postal_code', 'latitude', 'longitude',\n",
       "       'stars', 'review_count', 'is_open'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nightlife_businesses_PA = pd.read_csv('../data/processed/nightlife_business_PA.csv')\n",
    "nightlife_businesses_PA.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We decided to keep only the precise columns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "nightlife_businesses_PA = nightlife_businesses_PA.drop(columns=['Unnamed: 0', 'Category 1', 'Category 2',\n",
    "                                                                'Category 3', 'Category 4','Category 5',\n",
    "                                                                'Category 6', 'Category 7', 'Category 8',\n",
    "                                                                'Ambience', 'GoodForMeal', 'Music', 'BestNights',\n",
    "                                                                'address', 'city', 'state', 'is_open'])\n",
    "df_nighlife_PA_reviews = pd.merge(df_review_keywords, nightlife_businesses_PA, on='business_id')\n",
    "# Save the resulting DataFrame to a CSV file\n",
    "df_nighlife_PA_reviews.to_csv('../data/processed/df_nightlife_PA_reviews.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_id</th>\n",
       "      <th>user_id</th>\n",
       "      <th>business_id</th>\n",
       "      <th>stars_x</th>\n",
       "      <th>useful</th>\n",
       "      <th>funny</th>\n",
       "      <th>cool</th>\n",
       "      <th>date</th>\n",
       "      <th>keywords</th>\n",
       "      <th>BusinessAcceptsCreditCards</th>\n",
       "      <th>...</th>\n",
       "      <th>Thursday</th>\n",
       "      <th>Friday</th>\n",
       "      <th>Saturday</th>\n",
       "      <th>Sunday</th>\n",
       "      <th>name</th>\n",
       "      <th>postal_code</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>stars_y</th>\n",
       "      <th>review_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>oyaMhzBSwfGgemSGuZCdwQ</td>\n",
       "      <td>Dd1jQj7S-BFGqRbApFzCFw</td>\n",
       "      <td>YtSqYv1Q_pOltsVPSx54SA</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2013-06-24 11:21:25</td>\n",
       "      <td>['Tremendous', 'service', 'Big', 'shout', 'Dou...</td>\n",
       "      <td>True</td>\n",
       "      <td>...</td>\n",
       "      <td>16:30-22:0</td>\n",
       "      <td>16:30-22:0</td>\n",
       "      <td>16:30-22:0</td>\n",
       "      <td>16:30-22:0</td>\n",
       "      <td>Rittenhouse Grill</td>\n",
       "      <td>19103</td>\n",
       "      <td>39.948949</td>\n",
       "      <td>-75.169532</td>\n",
       "      <td>3.5</td>\n",
       "      <td>290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>iOQ_bnKI5HfPbH43DMAw6w</td>\n",
       "      <td>n0zPBuXxQuxHOQmA4ehcvQ</td>\n",
       "      <td>YtSqYv1Q_pOltsVPSx54SA</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2013-01-27 19:22:26</td>\n",
       "      <td>['good', 'place', 'lofty', 'prices', 'proporti...</td>\n",
       "      <td>True</td>\n",
       "      <td>...</td>\n",
       "      <td>16:30-22:0</td>\n",
       "      <td>16:30-22:0</td>\n",
       "      <td>16:30-22:0</td>\n",
       "      <td>16:30-22:0</td>\n",
       "      <td>Rittenhouse Grill</td>\n",
       "      <td>19103</td>\n",
       "      <td>39.948949</td>\n",
       "      <td>-75.169532</td>\n",
       "      <td>3.5</td>\n",
       "      <td>290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>rzrBiijeQh7ubjfRCr-UtA</td>\n",
       "      <td>Kj-u8Yq1d3mLKitWsDAxpg</td>\n",
       "      <td>YtSqYv1Q_pOltsVPSx54SA</td>\n",
       "      <td>4.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>2008-04-30 15:26:12</td>\n",
       "      <td>['bar', 'area', 'upscale', 'cities', 'restaura...</td>\n",
       "      <td>True</td>\n",
       "      <td>...</td>\n",
       "      <td>16:30-22:0</td>\n",
       "      <td>16:30-22:0</td>\n",
       "      <td>16:30-22:0</td>\n",
       "      <td>16:30-22:0</td>\n",
       "      <td>Rittenhouse Grill</td>\n",
       "      <td>19103</td>\n",
       "      <td>39.948949</td>\n",
       "      <td>-75.169532</td>\n",
       "      <td>3.5</td>\n",
       "      <td>290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1HP3yZN3jT646IlHSo7GZw</td>\n",
       "      <td>TBlVWr4kG22TU3fSW3rpRg</td>\n",
       "      <td>YtSqYv1Q_pOltsVPSx54SA</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2014-06-11 16:10:04</td>\n",
       "      <td>['prime', 'rib', 'steak', 'joints', 'experience']</td>\n",
       "      <td>True</td>\n",
       "      <td>...</td>\n",
       "      <td>16:30-22:0</td>\n",
       "      <td>16:30-22:0</td>\n",
       "      <td>16:30-22:0</td>\n",
       "      <td>16:30-22:0</td>\n",
       "      <td>Rittenhouse Grill</td>\n",
       "      <td>19103</td>\n",
       "      <td>39.948949</td>\n",
       "      <td>-75.169532</td>\n",
       "      <td>3.5</td>\n",
       "      <td>290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Vv6acqoztdtzTD8Gq0gifA</td>\n",
       "      <td>4-QufcPxbDllDwy_ktGNCA</td>\n",
       "      <td>YtSqYv1Q_pOltsVPSx54SA</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2018-03-04 00:43:27</td>\n",
       "      <td>['name', 'Best', 'Prime', 'Rib', 'town', 'Serv...</td>\n",
       "      <td>True</td>\n",
       "      <td>...</td>\n",
       "      <td>16:30-22:0</td>\n",
       "      <td>16:30-22:0</td>\n",
       "      <td>16:30-22:0</td>\n",
       "      <td>16:30-22:0</td>\n",
       "      <td>Rittenhouse Grill</td>\n",
       "      <td>19103</td>\n",
       "      <td>39.948949</td>\n",
       "      <td>-75.169532</td>\n",
       "      <td>3.5</td>\n",
       "      <td>290</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 56 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                review_id                 user_id             business_id  \\\n",
       "0  oyaMhzBSwfGgemSGuZCdwQ  Dd1jQj7S-BFGqRbApFzCFw  YtSqYv1Q_pOltsVPSx54SA   \n",
       "1  iOQ_bnKI5HfPbH43DMAw6w  n0zPBuXxQuxHOQmA4ehcvQ  YtSqYv1Q_pOltsVPSx54SA   \n",
       "2  rzrBiijeQh7ubjfRCr-UtA  Kj-u8Yq1d3mLKitWsDAxpg  YtSqYv1Q_pOltsVPSx54SA   \n",
       "3  1HP3yZN3jT646IlHSo7GZw  TBlVWr4kG22TU3fSW3rpRg  YtSqYv1Q_pOltsVPSx54SA   \n",
       "4  Vv6acqoztdtzTD8Gq0gifA  4-QufcPxbDllDwy_ktGNCA  YtSqYv1Q_pOltsVPSx54SA   \n",
       "\n",
       "   stars_x  useful  funny  cool                 date  \\\n",
       "0      5.0     0.0    0.0   0.0  2013-06-24 11:21:25   \n",
       "1      3.0     0.0    0.0   0.0  2013-01-27 19:22:26   \n",
       "2      4.0    12.0   11.0  11.0  2008-04-30 15:26:12   \n",
       "3      5.0     0.0    0.0   0.0  2014-06-11 16:10:04   \n",
       "4      5.0     0.0    0.0   0.0  2018-03-04 00:43:27   \n",
       "\n",
       "                                            keywords  \\\n",
       "0  ['Tremendous', 'service', 'Big', 'shout', 'Dou...   \n",
       "1  ['good', 'place', 'lofty', 'prices', 'proporti...   \n",
       "2  ['bar', 'area', 'upscale', 'cities', 'restaura...   \n",
       "3  ['prime', 'rib', 'steak', 'joints', 'experience']   \n",
       "4  ['name', 'Best', 'Prime', 'Rib', 'town', 'Serv...   \n",
       "\n",
       "  BusinessAcceptsCreditCards  ...    Thursday      Friday    Saturday  \\\n",
       "0                       True  ...  16:30-22:0  16:30-22:0  16:30-22:0   \n",
       "1                       True  ...  16:30-22:0  16:30-22:0  16:30-22:0   \n",
       "2                       True  ...  16:30-22:0  16:30-22:0  16:30-22:0   \n",
       "3                       True  ...  16:30-22:0  16:30-22:0  16:30-22:0   \n",
       "4                       True  ...  16:30-22:0  16:30-22:0  16:30-22:0   \n",
       "\n",
       "       Sunday               name postal_code   latitude  longitude stars_y  \\\n",
       "0  16:30-22:0  Rittenhouse Grill       19103  39.948949 -75.169532     3.5   \n",
       "1  16:30-22:0  Rittenhouse Grill       19103  39.948949 -75.169532     3.5   \n",
       "2  16:30-22:0  Rittenhouse Grill       19103  39.948949 -75.169532     3.5   \n",
       "3  16:30-22:0  Rittenhouse Grill       19103  39.948949 -75.169532     3.5   \n",
       "4  16:30-22:0  Rittenhouse Grill       19103  39.948949 -75.169532     3.5   \n",
       "\n",
       "  review_count  \n",
       "0          290  \n",
       "1          290  \n",
       "2          290  \n",
       "3          290  \n",
       "4          290  \n",
       "\n",
       "[5 rows x 56 columns]"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_nighlife_PA_reviews.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml_p3",
   "language": "python",
   "name": "ml_p3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
